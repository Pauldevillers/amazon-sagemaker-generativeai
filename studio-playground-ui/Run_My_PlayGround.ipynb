{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c7aa5e7",
   "metadata": {},
   "source": [
    "## Installation of Streamlit UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711c999-fb77-48da-a372-684e9a721758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95f3fa-1444-45a0-8e9d-ccfad7c3df8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import jinja2\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54511796-5e5d-401b-beb3-e37abb31eda3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "region = boto3.Session().region_name\n",
    "client = boto3.Session().client(\"sagemaker\")\n",
    "domainId=client.list_domains()[\"Domains\"][0].get(\"DomainId\")\n",
    "sess= sagemaker.session.Session()\n",
    "region = sess._region_name\n",
    "account_id = sess.account_id()\n",
    "\n",
    "vpc_id = client.describe_domain(\n",
    "    DomainId=client.list_domains()[\"Domains\"][0].get(\"DomainId\")\n",
    ").get(\"VpcId\")\n",
    "\n",
    "url = f\"https://{domainId}.studio.{region}.sagemaker.aws/jupyter/default/proxy/8501/\"\n",
    "print(url )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44550dfc",
   "metadata": {},
   "source": [
    "# Generative AI Prompt example with ``Falcon7B instruct``"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "767390e8",
   "metadata": {},
   "source": [
    "## Use Case : Report generation from structured data for Social networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa01f527",
   "metadata": {},
   "source": [
    "<p>Let's say you want to generate a report from structured data of social network users. You can once again utilize <b>few-shot prompting</b> to generate text based on predefined examples.\n",
    "\n",
    "In the example below, I have gathered fake JSON data about Twitter users along with their statistics.</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd3a2b05",
   "metadata": {},
   "source": [
    "```\n",
    "JSON\n",
    "{\n",
    "  \"username\": “Paul”,\n",
    "  \"platform\": \"Twitter\",\n",
    "  \"summary\": {\n",
    "    \"total_posts\": 150,\n",
    "    \"total_likes\": 1000,\n",
    "    \"total_retweets\": 500,\n",
    "    \"most_liked_post\": {\n",
    "      \"content\": “rugby game”,\n",
    "      \"likes\": 200,\n",
    "      \"retweets\": 50\n",
    "    },\n",
    "    \"most_retweeted_post\": {\n",
    "      \"content\": “can’t wait to see France vs New Zealand”,\n",
    "      \"likes\": 150,\n",
    "      \"retweets\": 100\n",
    "    },\n",
    "    \"engagement_rate\": 0.15\n",
    "  }\n",
    "}\n",
    "\n",
    "Text: \n",
    "Meet Paul, an active Twitter user who knows how to make an impact! With 150 posts, he has garnered an impressive 1000 likes and 500 retweets. Paul's top-notch content shines through, as his post about a rugby game scored a whopping 200 likes and 50 retweets. Not stopping there, his tweet expressing excitement for the France vs New Zealand match drew attention with 150 likes and 100 retweets. Talk about sparking conversations! With an engagement rate of 0.15, Paul is clearly making waves on Twitter. Keep up the great work, Paul!\n",
    "\n",
    "JSON:\n",
    "{\n",
    "  \"username\": “Ioan”,\n",
    "  \"platform\": \"Twitter\",\n",
    "  \"summary\": {\n",
    "    \"total_posts\":  4000,\n",
    "    \"total_likes\": 5000,\n",
    "    \"total_retweets\": 20,\n",
    "    \"most_liked_post\": {\n",
    "      \"content\": “GenAI in France”,\n",
    "      \"likes\": 2000,\n",
    "      \"retweets\": 500\n",
    "    },\n",
    "    \"most_retweeted_post\": {\n",
    "      \"content\": “can’t wait to see genAI immersion day”,\n",
    "      \"likes\": 1500,\n",
    "      \"retweets\": 100\n",
    "    },\n",
    "    \"engagement_rate\": 0.15\n",
    "  }\n",
    "}\n",
    "\n",
    "Text:\n",
    "Introducing Ioan, a Twitter enthusiast who knows how to make a splash! With a whopping 4000 posts, Ioan has managed to accumulate an impressive 5000 likes. While his retweet count stands at 20, Ioan's impact shines through his most liked post, \"GenAI in France,\" which received a staggering 2000 likes and 500 retweets. Additionally, his tweet expressing anticipation for \"genie immersion day\" gained traction with 1500 likes and 100 retweets. With an engagement rate of 0.15, Ioan's Twitter presence is undoubtedly making waves. Keep up the fantastic work, Ioan!\n",
    "\n",
    "JSON\n",
    "{\n",
    "  \"username\": “Albert”,\n",
    "  \"platform\": \"Twitter\",\n",
    "  \"summary\": {\n",
    "    \"total_posts\":  40,\n",
    "    \"total_likes\": 5,\n",
    "    \"total_retweets\": 20,\n",
    "    \"most_liked_post\": {\n",
    "      \"content\": “Devops”,\n",
    "      \"likes\": 2,\n",
    "      \"retweets\": 5\n",
    "    },\n",
    "    \"most_retweeted_post\": {\n",
    "      \"content\": “can’t wait to swim”,\n",
    "      \"likes\": 15,\n",
    "      \"retweets\": 1\n",
    "    },\n",
    "    \"engagement_rate\": 0.01\n",
    "  }\n",
    "}\n",
    "\n",
    "Text:\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6d109cc",
   "metadata": {},
   "source": [
    "## Use case: AWS expert chatbot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e07abc1",
   "metadata": {},
   "source": [
    "##### This decoder only model predicts next tokens, hence it won't stop unless you give it a stop word, in this case we can set the stop word option to `User:`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce1f0c66",
   "metadata": {},
   "source": [
    "Let's say we are building a friendly chat bot to start on AWS, we can levarage Falcon7B.\n",
    "```\n",
    "You are an helpful Assistant, called Falcon. Knowing everyting about AWS.\n",
    "\n",
    "User: Can you tell me something about Amazon SageMaker?\n",
    "Falcon:\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ddd7c66",
   "metadata": {},
   "source": [
    "You can also try with anther user prompt:\n",
    "\n",
    "```\n",
    "- How would you recommend start using Amazon SageMaker? If i am new to Machine Learning?\n",
    "- How would you recommend start using Amazon Lex? If i am new to chat bot application?\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4c35fab",
   "metadata": {},
   "source": [
    "# Other use cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3085b0f8",
   "metadata": {},
   "source": [
    "#### Text Generation\n",
    "- **Parameters** : max_new_tokens = 400 <p>\n",
    "```\n",
    "What is the recipe for a delicious lemon cheesecake?\n",
    "```\n",
    "                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b0192e9",
   "metadata": {},
   "source": [
    "#### Text Generation\n",
    "\n",
    "```\n",
    ">>QUESTION<< \n",
    "Building a website can be done in 10 simple steps\n",
    "\n",
    ">>ANSWER<<\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbff45c9",
   "metadata": {},
   "source": [
    "#### Summarize\n",
    "- **Parameters** : max_new_tokens = 200 <p>\n",
    "```\n",
    "Starting today, the state-of-the-art Falcon 40B foundation model from Technology\n",
    "Innovation Institute (TII) is available on Amazon SageMaker JumpStart, SageMaker's machine learning (ML) hub\n",
    "that offers pre-trained models, built-in algorithms, and pre-built solution templates to help you quickly get\n",
    "started with ML. You can deploy and use this Falcon LLM with a few clicks in SageMaker Studio or\n",
    "programmatically through the SageMaker Python SDK.\n",
    "Falcon 40B is a 40-billion-parameter large language model (LLM) available under the Apache 2.0 license that\n",
    "ranked #1 in Hugging Face Open LLM leaderboard, which tracks, ranks, and evaluates LLMs across multiple\n",
    "benchmarks to identify top performing models. Since its release in May 2023, Falcon 40B has demonstrated\n",
    "exceptional performance without specialized fine-tuning. To make it easier for customers to access this\n",
    "state-of-the-art model, AWS has made Falcon 40B available to customers via Amazon SageMaker JumpStart.\n",
    "Now customers can quickly and easily deploy their own Falcon 40B model and customize it to fit their specific\n",
    "needs for applications such as translation, question answering, and summarizing information.\n",
    "Falcon 40B are generally available today through Amazon SageMaker JumpStart in US East (Ohio),\n",
    "US East (N. Virginia), US West (Oregon), Asia Pacific (Tokyo), Asia Pacific (Seoul), Asia Pacific (Mumbai),\n",
    "Europe (London), Europe (Frankfurt), Europe (Ireland), and Canada (Central),\n",
    "with availability in additional AWS Regions coming soon. To learn how to use this new feature,\n",
    "please see SageMaker JumpStart documentation, the Introduction to SageMaker JumpStart –\n",
    "Text Generation with Falcon LLMs example notebook, and the blog Technology Innovation Institute trainsthe\n",
    "state-of-the-art Falcon LLM 40B foundation model on Amazon SageMaker. Summarize the article above:\n",
    "```\n",
    "      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b08f3498",
   "metadata": {},
   "source": [
    "# Generative AI Prompt example with ``FLAN-T5-XXL instruct``"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48a64364",
   "metadata": {},
   "source": [
    "## Use Case: Yes/No answering for allowed & prohibited items at events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f221268",
   "metadata": {},
   "source": [
    "<p>Let's say you want to buid a Yes/No question answering to enhanced user experience for allowed and prohibited items at large events (festival, sport games, ect) You can use <b> zero shot prompting </b> to provider clear answer to customer\n",
    "\n",
    "In the example below, I've collected help page from [Lolapalooza festival](https://support.lollapalooza.com/hc/en-us/articles/4402082688020-What-items-are-allowed-prohibited-at-Lollapalooza-) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3ad986a",
   "metadata": {},
   "source": [
    "```\n",
    "Given context below,  answer yes or no to question  : Can I bring water ?\n",
    "\n",
    "Context: \n",
    "\n",
    "Guests and their belongings are subject to search upon entry or re-entry. You can help keep the lines moving quickly by leaving large bags at home.\n",
    "\n",
    "The following items are ALLOWED:\n",
    "\n",
    "CLEAR bags made up of clear plastic, vinyl, or pvc, and no larger than 12\" x 6\" x 12\". Small clutch purses and fanny packs with no more than 1 pocket.  Clutch purses no larger than 6\" x 9\" (See Full Bag Policy Below)\n",
    "Baby Strollers\n",
    "Frisbees\n",
    "Binoculars\n",
    "Blankets, Sheets, Towels\n",
    "Cameras (basic point and shoot consumer-grade cameras) without detachable lenses and other accessories (monopods, selfie sticks, tripods, GoPro mounts, and other attachments are not allowed)\n",
    "EMPTY reusable water bottles and hydration packs, and plastic or aluminum water bottles\n",
    "Sunscreen in non-aerosol containers is allowed in the size of 3.4 ounces or less\n",
    "Factory sealed Naloxone/Narcan kit\n",
    "Prescription Medicine Requirements: \n",
    "\n",
    "Anyone needing prescription medicine at the festival must present the pharmacy-labeled container which states the prescription, dosage, and patient name to our medical staff at each entrance gate. Patrons are only allowed a sufficient supply of the prescribed medication for that day.\n",
    "Medicines needing to be inhaled or smoked are prohibited unless in a prescribed inhaler.\n",
    "Over the counter medications are allowed in a sufficient supply for the day. Bottle contents will be verified by medical personnel at the entry gates.\n",
    " \n",
    "\n",
    "The following items are PROHIBITED:\n",
    "\n",
    "Any bags that are NOT CLEAR bags made up of clear plastic, vinyl, or pvc, and are larger than 12\" x 6\" x 12\". Any Small clutch purses and fanny packs with more than 1 pocket.  Clutch purses that are larger than 6\" x 9\" (See Full Bag Policy Below)\n",
    "Aerosol containers, including sunscreen and personal beauty products. NOTE: Sunscreen in non-aerosol containers is allowed in the size of 3.4 ounces or less\n",
    "Coolers of any kind. (Exceptions may be made for medical use)\n",
    "Framed backpacks, multiple pocket back packs and any pack that is not aligned with the allowed backpacks above. (See Full Bag Policy Below)\n",
    "Any and all professional audio recording equipment\n",
    "Professional cameras and professional recording (photo, video, audio) equipment (NO large professional detachable zoom lenses, stands, monopods, tripods, attachment sticks (selfie sticks) or other commercial equipment.\n",
    "Any and all professional video equipment. No video recording will be allowed\n",
    "Drones or any other remote flying device\n",
    "Hammocks\n",
    "Glass containers of any kind\n",
    "Illegal and Illicit substances of any kind\n",
    "Outside food or beverage (including alcohol) of any kind\n",
    "Umbrellas\n",
    "Pets (except service animals)\n",
    "Selfie sticks\n",
    "Skateboards, scooters, bicycles, wagons, carts or any personal motorized vehicles\n",
    "Tents, canopies, or shade structures of any kind\n",
    "Unauthorized/unlicensed vendors are not allowed. No unauthorized solicitation and materials including handbills, flyers, stickers, beach balls, giveaways, samples, etc.\n",
    "Weapons or explosives of any kind\n",
    "Fireworks\n",
    "Large chains or spiked jewelry\n",
    "Bicycles inside festival grounds (free parking is available near festival entrance)\n",
    "Carts of any kind (including Red Wagons)\n",
    "Chairs of any kind\n",
    "All Chicago parks prohibit smoking of any kind, including vaping.\n",
    "FULL BAG POLICY:\n",
    "\n",
    "ALL bags will be searched before entry.\n",
    "Small clutch purses and fanny packs that are 6\" x 9\" or smaller do not need to be clear, but can have no more than one pocket.\n",
    "All other bags larger than 6\" x 9\" must be smaller than 12\" x 6\" x 12\" and clear.\n",
    "Hydration packs are allowed and do not need to be clear, but must be emptied of all liquid and have no more than two pockets in addition to the one holding the water reservoir.\n",
    "To speed up entry, leave your bags at home, and take advantage of Lolla’s No Bag Express Lanes.\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc24a382",
   "metadata": {},
   "source": [
    "You can also ask these questions to test the model : \n",
    "- Can I bring a dog ?\n",
    "- I am blind, so can I bring a dog ?\n",
    "- I am blind, so can I bring a tiger ?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbeed543",
   "metadata": {},
   "source": [
    "## Use case : Data extraction for Sport News"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb9e2304",
   "metadata": {},
   "source": [
    "<p>Let's say you want to extract structured data from sport news. You can use <b>few shot prompting</b> to extract relevant information such as names, dates, numbers, ect </p> \n",
    "\n",
    "In the example below,I've collected news about soccer [transfer information](https://twitter.com/FabrizioRomano) and the goal is to extract a structured JSON document with :\n",
    "- Sport\n",
    "- Person involve in the transfer\n",
    "- Club\n",
    "- Money involve "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "feb6429d",
   "metadata": {},
   "source": [
    "```\n",
    "[Text] : West Ham have just communicated to Arsenal that they’re accepting £100m plus £5m add-ons fee for Declan Rice. The two clubs remain in talks over deal structure & payment terms — as West Ham want £100m to be paid within 18 months. Final discussions and then… done deal.\n",
    "\n",
    "[JSON] : { \"sport\" : \"foot\", \"who\":\"Declan Rice\", \"club\" :\" West Ham\" ,\"money\":  \"£100m\" }\n",
    "\n",
    "[Text] : BREAKING: Manchester United agree £60m package deal for Mason Mount with Chelsea — it’s done, here we go! #MUFC Personal terms agreed weeks ago and face to face talks between clubs made it clear: the agreement is done. Mount becomes Utd player — they NEVER left the race.\n",
    "\n",
    "\n",
    "[JSON] : {\"sport\" : \"foot\", \"who\": \"Mason Mount\", \"club:Manchester United\",  \"money\":   \"£60m\" }\n",
    "\n",
    "[Text] : James Maddison has completed first part of medical tests as new Tottenham player, as expected. . #THFC £40m deal to be announced soon — here we go confirmed.\n",
    "\n",
    "[JSON] :{\"sport\" :\" foot\", \"who\": \"James Maddison\" : \"club\": \"Tottenham\" , \"money\":   \"£60m\" }\n",
    "\n",
    "[Text] : Manchester United had new direct talks to be informed on André Onana deal in the last 24 hours. He’s highly rated by Erik ten Hag. 🔴🇨🇲 #MUFC. Man Utd, still waiting to clarify David de Gea situation before deciding on official proposal.Inter want at least €50/55m.\n",
    "\n",
    "\n",
    "[JSON] : {\"sport\" : \"foot\", \"who\": \"David De Gea/André Onana\"  , \"club\" : \"Manchester United\" , \"money\": \"€50/55\"}\n",
    "\n",
    "[Text] : Medical scheduled for Harry Winks to join Tottenham on permanent deal from  Leicester City for £10m fee. 🔵🦊 #LCFC. Separated deal from Maddison but one more set to be completed.\n",
    "\n",
    "[JSON] :\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82bd4076",
   "metadata": {},
   "source": [
    "## Use case : Data extraction for online user orders "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2375be0e",
   "metadata": {},
   "source": [
    "<p>Let's say you want to extract structured data from user orders. You can use <b>Chain of thoughts (CoT) </b> to extract relevant information such as Price, Resolution, deliverDays </p> \n",
    "\n",
    "In the example below,I've collected user orders and the goal is to extract a structured JSON document with :\n",
    "- minimumPrice\n",
    "- maximumPrice\n",
    "- deliverInDays\n",
    "- resolution\n",
    "- sizeFrom\n",
    "- sizeTo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ea949f1",
   "metadata": {},
   "source": [
    "```\n",
    "You are given the below typescript schema:\n",
    "\n",
    "type Resolution = '8K' | '4K' | '1080p' | '720p'\n",
    "\n",
    "interface TvSearchQuery {\n",
    "    minimumPrice?: Number;\n",
    "    maximumPrice?: Number;\n",
    "    deliverInDays?: Number;\n",
    "    resolution?: Resolution;\n",
    "    sizeFrom?: Number;\n",
    "    sizeTo?: Number;\n",
    "}\n",
    "\n",
    "Analyze user's asking, and then using this documentation, generate a complete json\n",
    " object matching the schema for answering the user's asking. Prefer simpler searches\n",
    " unless specified in the user's question.\n",
    " \n",
    " \n",
    "[Asking]: I want to order a TV with 55 inches or bigger, delivered within 2 days. My budget is $2000.\n",
    "\n",
    "[Answer]: size is from 55. deliverInDays is 2. price is up to 2000. Generated json object is { \"maximumPrice\": 2000, \"deliverInDays\": 2, \"sizeFrom\": 55 }\n",
    "\n",
    "\n",
    "[Asking] : I want 8K or 4K TV under $3000.\n",
    "\n",
    "[Answer] : resolution is 8K or 4K. price is up to 3000. Generated json object is { \"maximumPrice\": 3000, \"resolution\": [\"8K\", \"4K\"] }\n",
    "\n",
    "\n",
    "[Asking] : a 4K TV needed in 3 days.\n",
    "\n",
    "[Answer] : price is not specified. resolution is 4K. deliverInDays is 3. Generated json object is\n",
    "{ \"deliverInDays\": 3, \"resolution\": [\"4K\"] }\n",
    "\n",
    "\n",
    "[Asking] : a 1080p TV needed in 5 days.\n",
    "\n",
    "[Answer] : price is not specified. resolution is 1080p. deliverInDays is 5. Generated json object is { \"deliverInDays\": 5, \"resolution\": [\"1080p\"] }\n",
    "\n",
    "\n",
    "[Asking] : I want 1080p or 4K TV over $500. I want it in 3 days.\n",
    "\n",
    "[Answer] : \n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bca2ceff",
   "metadata": {},
   "source": [
    "## Use case : Question answering for live news"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7560abdb",
   "metadata": {},
   "source": [
    "We can also use Flan-T5-XXL to perfom question answering on text using **zero shot prompting**, here is a news example with [AI news](https://www.bbc.co.uk/news/business-66042169)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03b8c0c1",
   "metadata": {},
   "source": [
    "```\n",
    "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    " There is a lot of rubbish in the world. Approximately 2.24 billion tonnes of solid waste was produced in 2020, according to the World Bank. It says the figure is likely to rise by 73% to 3.88 billion tonnes by 2050.Plastic is particularly problematic. From the start of large-scale production of the material in the 1950s until 2015, more than 8.3 billion tonnes of plastic waste was produced, research from the Universities of Georgia and California calculated.\n",
    "\n",
    "Someone who will not find those statistics surprising is Mikela Druckman. She has spent a lot of time looking at what we throw away, as the founder of Greyparrot, a UK start-up that has created an AI system designed to analyse waste processing and recycling facilities.\n",
    "\n",
    "\"In a single day you will have literally mountains of waste in one facility coming through, and what's very shocking and surprising is that it never stops,\" she says. There are no holidays for waste, it just keeps coming.\"\n",
    "\n",
    "Greyparrot places cameras above the conveyor belts of around 50 waste and recycling sites in Europe, utilising AI software to analyse what passes through in real-time.\n",
    "\n",
    "Réponds en Français : \n",
    "Question :  Combien de déchets plastiques ont été produits en 2020 ?\n",
    " \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fad812ee",
   "metadata": {},
   "source": [
    "#### Deal with hallucinations with Chain of thougts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f06ec2ca",
   "metadata": {},
   "source": [
    "Now you can try to ask about data that does not exist such as :\n",
    "- Combien de plastiques ont été produits en 2020 ?\n",
    "\n",
    "Indeed, you can see that the model hallucinates the response, to avoid this behavior we can use Chain of thoughts. Add prompt below \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    " There is a lot of rubbish in the world. Approximately 2.24 billion tonnes of solid waste was produced in 2020, according to the World Bank. It says the figure is likely to rise by 73% to 3.88 billion tonnes by 2050.Plastic is particularly problematic. From the start of large-scale production of the material in the 1950s until 2015, more than 8.3 billion tonnes of plastic waste was produced, research from the Universities of Georgia and California calculated.\n",
    "\n",
    "Someone who will not find those statistics surprising is Mikela Druckman. She has spent a lot of time looking at what we throw away, as the founder of Greyparrot, a UK start-up that has created an AI system designed to analyse waste processing and recycling facilities.\n",
    "\n",
    "\"In a single day you will have literally mountains of waste in one facility coming through, and what's very shocking and surprising is that it never stops,\" she says. There are no holidays for waste, it just keeps coming.\"\n",
    "\n",
    "Greyparrot places cameras above the conveyor belts of around 50 waste and recycling sites in Europe, utilising AI software to analyse what passes through in real-time.\n",
    "\n",
    "Réponds en Français : \n",
    "Question :  Combien de plastiques ont été produits en 2023 ?\n",
    "Réponse : Je ne sais pas car j'ai des données seulement pour 2020\n",
    "\n",
    "Question :  Combien de plastiques ont été produits en 2034 ?\n",
    "Réponse : \n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe39ddec",
   "metadata": {},
   "source": [
    "You can also ask these questions : \n",
    "- What is the projected increase in solid waste production by 2050?\n",
    "- How much plastic waste was produced between the 1950s and 2015?\n",
    "- What is the purpose of Greyparrot's AI system?\n",
    "- How does Greyparrot utilize cameras and AI software in waste and recycling sites?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88516125",
   "metadata": {},
   "source": [
    "### Supported parameters\n",
    "\n",
    "***\n",
    "Some of the supported parameters while performing inference are the following:\n",
    "\n",
    "* **max_length:** Model generates text until the output length (which includes the input context length) reaches `max_length`. If specified, it must be a positive integer.\n",
    "* **max_new_tokens:** Model generates text until the output length (excluding the input context length) reaches `max_new_tokens`. If specified, it must be a positive integer.\n",
    "* **num_beams:** Number of beams used in the greedy search. If specified, it must be integer greater than or equal to `num_return_sequences`.\n",
    "* **no_repeat_ngram_size:** Model ensures that a sequence of words of `no_repeat_ngram_size` is not repeated in the output sequence. If specified, it must be a positive integer greater than 1.\n",
    "* **temperature:** Controls the randomness in the output. Higher temperature results in output sequence with low-probability words and lower temperature results in output sequence with high-probability words. If `temperature` -> 0, it results in greedy decoding. If specified, it must be a positive float.\n",
    "* **early_stopping:** If True, text generation is finished when all beam hypotheses reach the end of sentence token. If specified, it must be boolean.\n",
    "* **do_sample:** If True, sample the next word as per the likelihood. If specified, it must be boolean.\n",
    "* **top_k:** In each step of text generation, sample from only the `top_k` most likely words. If specified, it must be a positive integer.\n",
    "* **top_p:** In each step of text generation, sample from the smallest possible set of words with cumulative probability `top_p`. If specified, it must be a float between 0 and 1.\n",
    "* **return_full_text:** If True, input text will be part of the output generated text. If specified, it must be boolean. The default value for it is False.\n",
    "* **stop**: If specified, it must a list of strings. Text generation stops if any one of the specified strings is generated.\n",
    "\n",
    "We may specify any subset of the parameters mentioned above while invoking an endpoint. \n",
    "\n",
    "For more parameters and information on HF LLM DLC, please see [this article](https://huggingface.co/blog/sagemaker-huggingface-llm#4-run-inference-and-chat-with-our-model).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ab551",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
