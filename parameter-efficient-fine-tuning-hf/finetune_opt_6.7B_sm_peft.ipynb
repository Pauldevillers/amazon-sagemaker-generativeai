{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aabfbe39-453a-48b0-bc9e-ad9df77e9081",
   "metadata": {},
   "source": [
    "## Fine-tuning Billion Scale Generative AI model using HuggingFace PEFT Library on SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dea133-3319-4b64-845e-9af8fde89ad7",
   "metadata": {},
   "source": [
    " “Generative AI refers to artificial intelligence that can generate novel content, rather than simply analyzing or acting on existing data.” by Brandon Kaplan\n",
    " \n",
    "This is in contrast with discriminative models which classify data. The ability of generative models to generate content makes them extremely useful for applications like text generation, image generation, and speech generation.\n",
    "\n",
    "While generative models have many advantages, they are also very complex and large in size. A generative model usually have large number of parameters which describe the model’s internal dynamics as well as the features of the data the model generates. \n",
    "\n",
    "Conventional paradigm is large-scale pretraining on generic large scale data, followed by fine-tuning to downstream tasks. Fine-tuning these pretrained LLMs on downstream datasets results in huge performance gains when compared to using the pretrained LLMs out-of-the-box (zero-shot inference, for example). However, training these large models even with fine-tune datasets which are relatively smaller in size, requires lot of compute as the models might not be able to fit in a single GPU memory along with the batch of data on which it is trained. Additionally, storing and deploying fine-tuned models is also very expensive as they are the same size as orginal models. \n",
    "\n",
    "In order to overcome this challenge and to optimize for cost, where you can use consumer hardware for fine-tuning, parameter effitient fine tuning (PEFT) approaches are used. \n",
    "\n",
    "In this notebook we will cover how we can fine-tune large language models using the very recent `peft` library and `bitsandbytes` for loading large models in 8-bit.\n",
    "The fine-tuning method will rely on a recent method called \"Low Rank Adapters\" (LoRA), instead of fine-tuning the entire model you just have to fine-tune these adapters and load them properly inside the model. \n",
    "\n",
    "References: \n",
    "https://github.com/huggingface/peft/tree/main/examples/int8_training\n",
    "https://huggingface.co/blog/peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf307c1e-391a-4de6-8551-bfea10df9276",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c60b999-2acd-4261-a882-f15935353ada",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker==2.123.0\n",
      "  Using cached sagemaker-2.123.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker==2.123.0) (3.19.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from sagemaker==2.123.0) (1.4.1)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker==2.123.0) (1.0.1)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker==2.123.0) (0.2.8)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker==2.123.0) (0.2.0)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker==2.123.0) (20.3.0)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker==2.123.0) (4.11.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker==2.123.0) (1.22.2)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.8/site-packages (from sagemaker==2.123.0) (0.1.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker==2.123.0) (21.3)\n",
      "Collecting schema\n",
      "  Using cached schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Collecting boto3<2.0,>=1.26.28\n",
      "  Downloading boto3-1.26.80-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
      "  Using cached s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
      "Collecting botocore<1.30.0,>=1.29.80\n",
      "  Downloading botocore-1.29.80-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3<2.0,>=1.26.28->sagemaker==2.123.0) (0.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker==2.123.0) (3.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->sagemaker==2.123.0) (3.0.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker==2.123.0) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker==2.123.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->sagemaker==2.123.0) (2021.3)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker==2.123.0) (1.6.6.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker==2.123.0) (0.3.0)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker==2.123.0) (0.70.12.2)\n",
      "Requirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker==2.123.0) (0.3.4)\n",
      "Collecting contextlib2>=0.5.5\n",
      "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.30.0,>=1.29.80->boto3<2.0,>=1.26.28->sagemaker==2.123.0) (1.26.8)\n",
      "Installing collected packages: contextlib2, schema, botocore, s3transfer, boto3, sagemaker\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.24.13\n",
      "    Uninstalling botocore-1.24.13:\n",
      "      Successfully uninstalled botocore-1.24.13\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.5.2\n",
      "    Uninstalling s3transfer-0.5.2:\n",
      "      Successfully uninstalled s3transfer-0.5.2\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.21.13\n",
      "    Uninstalling boto3-1.21.13:\n",
      "      Successfully uninstalled boto3-1.21.13\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.77.1\n",
      "    Uninstalling sagemaker-2.77.1:\n",
      "      Successfully uninstalled sagemaker-2.77.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.22.68 requires botocore==1.24.13, but you have botocore 1.29.80 which is incompatible.\n",
      "awscli 1.22.68 requires s3transfer<0.6.0,>=0.5.0, but you have s3transfer 0.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.26.80 botocore-1.29.80 contextlib2-21.6.0 s3transfer-0.6.0 sagemaker-2.123.0 schema-0.7.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker==2.123.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c77a7659-a9c8-403f-af4b-b709540dda3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.123.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb4e8ea-3c54-4a4a-a7ab-3bda4aef5bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Amazon Resource Name (ARN) of the role used for this demo is: arn:aws:iam::706553727873:role/SagemakerEMRNoAuthProductWi-SageMakerExecutionRole-I48AJ9D41LXR\n",
      "The name of the role used for this demo is: SagemakerEMRNoAuthProductWi-SageMakerExecutionRole-I48AJ9D41LXR\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "role_name = role.split([\"/\"][-1])\n",
    "print(f\"The Amazon Resource Name (ARN) of the role used for this demo is: {role}\")\n",
    "print(f\"The name of the role used for this demo is: {role_name[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b5037-abda-4c96-8549-4136fb139454",
   "metadata": {},
   "source": [
    "## Fine-tuning OPT6.7B model from HuggingFace hub which is approximately 13GB in size \n",
    "The following training job will give the `out of memory error (OOM)` on `ml.g5.2xlarge` GPU, as it only has 1GPU and 24GB of GPU memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d6e0ae3-0e5d-4938-960e-fe7aa4275b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fine tuning model with \n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "estimator = HuggingFace(\n",
    "    base_job_name=\"hf-peft-optj6\",\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"train-fine-tune.py\",\n",
    "    role=role,\n",
    "    transformers_version='4.17',\n",
    "    pytorch_version='1.10',\n",
    "    py_version='py38',\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\", # relatively smaller GPU\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    debugger_hook_config=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0b7ea15-f83f-4758-8609-f57d06f13281",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: hf-peft-optj6-2023-02-27-19-46-06-030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-27 19:46:06 Starting - Starting the training job...\n",
      "2023-02-27 19:46:30 Starting - Preparing the instances for trainingProfilerReport-1677527166: InProgress\n",
      "......\n",
      "2023-02-27 19:47:35 Downloading - Downloading input data\n",
      "2023-02-27 19:47:35 Training - Downloading the training image.....................\n",
      "2023-02-27 19:51:07 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-02-27 19:51:40,743 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-02-27 19:51:40,763 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-02-27 19:51:40,765 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-02-27 19:51:40,947 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.37.0-py3-none-any.whl (76.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.3/76.3 MB 38.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.18.4)\u001b[0m\n",
      "\u001b[34mCollecting accelerate\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.16.0-py3-none-any.whl (199 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.7/199.7 kB 37.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting loralib\u001b[0m\n",
      "\u001b[34mDownloading loralib-0.1.1-py3-none-any.whl (8.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting ipywidgets\u001b[0m\n",
      "\u001b[34mDownloading ipywidgets-8.0.4-py3-none-any.whl (137 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.8/137.8 kB 34.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 2)) (3.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 2)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 2)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 2)) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 2)) (0.70.13)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 2)) (1.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 2)) (2022.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 2)) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 2)) (4.64.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 2)) (1.22.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 2)) (0.3.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 2)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 2)) (9.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 3)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 3)) (5.9.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from accelerate->-r requirements.txt (line 3)) (1.10.2+cu113)\u001b[0m\n",
      "\u001b[34mCollecting widgetsnbextension~=4.0\u001b[0m\n",
      "\u001b[34mDownloading widgetsnbextension-4.0.5-py3-none-any.whl (2.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 114.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 5)) (8.0.1)\u001b[0m\n",
      "\u001b[34mCollecting ipykernel>=4.5.1\u001b[0m\n",
      "\u001b[34mDownloading ipykernel-6.21.2-py3-none-any.whl (149 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 149.7/149.7 kB 28.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting jupyterlab-widgets~=3.0\u001b[0m\n",
      "\u001b[34mDownloading jupyterlab_widgets-3.0.5-py3-none-any.whl (384 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 384.3/384.3 kB 61.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 5)) (5.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (6.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (2.0.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (21.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r requirements.txt (line 2)) (3.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r requirements.txt (line 2)) (4.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (6.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (0.1.6)\u001b[0m\n",
      "\u001b[34mCollecting jupyter-core!=5.0.*,>=4.12\u001b[0m\n",
      "\u001b[34mDownloading jupyter_core-5.2.0-py3-none-any.whl (94 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.3/94.3 kB 28.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (24.0.1)\u001b[0m\n",
      "\u001b[34mCollecting jupyter-client>=6.1.12\u001b[0m\n",
      "\u001b[34mDownloading jupyter_client-8.0.3-py3-none-any.whl (102 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.7/102.7 kB 27.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting debugpy>=1.6.5\u001b[0m\n",
      "\u001b[34mDownloading debugpy-1.6.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 123.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting comm>=0.1.1\u001b[0m\n",
      "\u001b[34mDownloading comm-0.1.2-py3-none-any.whl (6.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting nest-asyncio\u001b[0m\n",
      "\u001b[34mDownloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (2.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (65.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: black in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (22.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: stack-data in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (3.0.31)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (5.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.7.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets->-r requirements.txt (line 2)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (1.26.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (2022.9.24)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 2)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2022.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.8.3 in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (4.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (2.5.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.2.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (8.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from black->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.10.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: executing in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pure-eval in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (0.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: asttokens in /opt/conda/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 5)) (2.0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 5)) (3.8.1)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: bitsandbytes, widgetsnbextension, nest-asyncio, loralib, jupyterlab-widgets, jupyter-core, debugpy, comm, jupyter-client, accelerate, ipykernel, ipywidgets\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.16.0 bitsandbytes-0.37.0 comm-0.1.2 debugpy-1.6.6 ipykernel-6.21.2 ipywidgets-8.0.4 jupyter-client-8.0.3 jupyter-core-5.2.0 jupyterlab-widgets-3.0.5 loralib-0.1.1 nest-asyncio-1.5.6 widgetsnbextension-4.0.5\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 23.0.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-02-27 19:51:46,603 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-02-27 19:51:46,603 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-02-27 19:51:46,666 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"hf-peft-optj6-2023-02-27-19-46-06-030\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-706553727873/hf-peft-optj6-2023-02-27-19-46-06-030/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train-fine-tune\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train-fine-tune.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train-fine-tune.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train-fine-tune\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-706553727873/hf-peft-optj6-2023-02-27-19-46-06-030/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"hf-peft-optj6-2023-02-27-19-46-06-030\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-706553727873/hf-peft-optj6-2023-02-27-19-46-06-030/source/sourcedir.tar.gz\",\"module_name\":\"train-fine-tune\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train-fine-tune.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.22b20220929-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 train-fine-tune.py\u001b[0m\n",
      "\u001b[34mCollecting git+https://github.com/huggingface/transformers.git@main\u001b[0m\n",
      "\u001b[34mCloning https://github.com/huggingface/transformers.git (to revision main) to /tmp/pip-req-build-ky1ebtc5\u001b[0m\n",
      "\u001b[34mRunning command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-ky1ebtc5\u001b[0m\n",
      "\u001b[34mResolved https://github.com/huggingface/transformers.git to commit f95f60c8293cf64355f1d212fe7e8f8fd4e3b770\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.11.0\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.3/190.3 kB 28.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (2022.9.13)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (0.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (3.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (4.64.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (1.22.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.27.0.dev0) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev0) (4.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.27.0.dev0) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.27.0.dev0) (1.26.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.27.0.dev0) (2022.9.24)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.27.0.dev0) (2.0.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.27.0.dev0) (3.3)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: transformers\u001b[0m\n",
      "\u001b[34mBuilding wheel for transformers (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for transformers (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for transformers: filename=transformers-4.27.0.dev0-py3-none-any.whl size=6630690 sha256=8e7341f9ba02145b245c821491f236f464a345f2df670a8e41745a43a9a41cd1\u001b[0m\n",
      "\u001b[34mStored in directory: /tmp/pip-ephem-wheel-cache-9bcpne6z/wheels/0c/f1/cf/0c84f8631406672e9adab41401961ab0d771b0b9c6f7195624\u001b[0m\n",
      "\u001b[34mSuccessfully built transformers\u001b[0m\n",
      "\u001b[34mInstalling collected packages: huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.10.0\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.10.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.10.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.17.0\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.17.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.17.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed huggingface-hub-0.12.1 transformers-4.27.0.dev0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 23.0.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m===================================BUG REPORT===================================\u001b[0m\n",
      "\u001b[34mWelcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\u001b[0m\n",
      "\u001b[34m================================================================================\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json:   0%|          | 0.00/651 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json: 100%|██████████| 651/651 [00:00<00:00, 179kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)model.bin.index.json:   0%|          | 0.00/41.9k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)model.bin.index.json: 100%|██████████| 41.9k/41.9k [00:00<00:00, 11.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   0%|          | 0.00/9.96G [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   0%|          | 21.0M/9.96G [00:00<00:55, 178MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   1%|          | 52.4M/9.96G [00:00<00:42, 234MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   1%|          | 83.9M/9.96G [00:00<00:48, 205MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   1%|          | 115M/9.96G [00:00<00:42, 230MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   1%|▏         | 147M/9.96G [00:00<00:38, 255MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   2%|▏         | 178M/9.96G [00:00<00:38, 253MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   2%|▏         | 220M/9.96G [00:00<00:34, 286MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   3%|▎         | 262M/9.96G [00:00<00:31, 309MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   3%|▎         | 294M/9.96G [00:01<00:37, 260MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   3%|▎         | 336M/9.96G [00:01<00:34, 281MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   4%|▍         | 377M/9.96G [00:01<00:32, 292MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   4%|▍         | 419M/9.96G [00:01<00:30, 310MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   5%|▍         | 461M/9.96G [00:01<00:29, 319MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   5%|▌         | 503M/9.96G [00:01<00:28, 330MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   5%|▌         | 545M/9.96G [00:01<00:28, 336MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   6%|▌         | 587M/9.96G [00:02<00:28, 333MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   6%|▋         | 629M/9.96G [00:02<00:27, 336MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   7%|▋         | 671M/9.96G [00:02<00:28, 320MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   7%|▋         | 713M/9.96G [00:02<00:28, 327MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   8%|▊         | 755M/9.96G [00:02<00:29, 311MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   8%|▊         | 797M/9.96G [00:02<00:29, 314MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   8%|▊         | 839M/9.96G [00:02<00:30, 297MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   9%|▊         | 870M/9.96G [00:02<00:30, 301MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   9%|▉         | 902M/9.96G [00:03<00:29, 303MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:   9%|▉         | 933M/9.96G [00:03<00:30, 298MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  10%|▉         | 975M/9.96G [00:03<00:29, 306MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  10%|█         | 1.01G/9.96G [00:03<00:32, 272MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  10%|█         | 1.04G/9.96G [00:03<00:38, 232MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  11%|█         | 1.08G/9.96G [00:03<00:34, 257MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  11%|█▏        | 1.12G/9.96G [00:03<00:31, 277MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  12%|█▏        | 1.16G/9.96G [00:04<00:30, 288MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  12%|█▏        | 1.21G/9.96G [00:04<00:29, 297MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  13%|█▎        | 1.25G/9.96G [00:04<00:28, 304MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  13%|█▎        | 1.29G/9.96G [00:04<00:28, 309MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  13%|█▎        | 1.33G/9.96G [00:04<00:27, 314MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  14%|█▍        | 1.37G/9.96G [00:04<00:29, 290MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  14%|█▍        | 1.41G/9.96G [00:04<00:33, 258MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  14%|█▍        | 1.44G/9.96G [00:05<00:35, 240MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  15%|█▍        | 1.47G/9.96G [00:05<00:37, 228MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  15%|█▌        | 1.50G/9.96G [00:05<00:38, 222MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  15%|█▌        | 1.53G/9.96G [00:05<00:39, 215MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  16%|█▌        | 1.56G/9.96G [00:05<00:40, 208MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  16%|█▌        | 1.59G/9.96G [00:05<00:38, 218MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  16%|█▋        | 1.63G/9.96G [00:05<00:35, 233MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  17%|█▋        | 1.66G/9.96G [00:06<00:34, 244MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  17%|█▋        | 1.69G/9.96G [00:06<00:32, 253MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  17%|█▋        | 1.72G/9.96G [00:06<00:31, 263MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  18%|█▊        | 1.75G/9.96G [00:06<00:30, 268MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  18%|█▊        | 1.78G/9.96G [00:06<00:30, 269MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  18%|█▊        | 1.81G/9.96G [00:06<00:31, 262MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  19%|█▊        | 1.85G/9.96G [00:06<00:31, 259MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  19%|█▉        | 1.88G/9.96G [00:06<00:32, 247MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  19%|█▉        | 1.91G/9.96G [00:06<00:33, 241MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  19%|█▉        | 1.94G/9.96G [00:07<00:33, 242MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  20%|█▉        | 1.97G/9.96G [00:07<00:33, 239MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  20%|██        | 2.00G/9.96G [00:07<00:32, 247MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  20%|██        | 2.03G/9.96G [00:07<00:31, 249MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  21%|██        | 2.07G/9.96G [00:07<00:31, 252MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  21%|██        | 2.10G/9.96G [00:07<00:30, 258MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  21%|██▏       | 2.13G/9.96G [00:07<00:30, 261MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  22%|██▏       | 2.16G/9.96G [00:07<00:29, 261MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  22%|██▏       | 2.19G/9.96G [00:08<00:29, 264MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  22%|██▏       | 2.22G/9.96G [00:08<00:29, 266MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  23%|██▎       | 2.25G/9.96G [00:08<00:28, 266MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  23%|██▎       | 2.29G/9.96G [00:08<00:28, 270MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  23%|██▎       | 2.32G/9.96G [00:08<00:28, 271MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  24%|██▎       | 2.35G/9.96G [00:08<00:27, 272MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  24%|██▍       | 2.38G/9.96G [00:08<00:28, 270MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  24%|██▍       | 2.41G/9.96G [00:08<00:27, 271MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  25%|██▍       | 2.44G/9.96G [00:09<00:27, 273MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  25%|██▍       | 2.47G/9.96G [00:09<00:29, 255MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  25%|██▌       | 2.51G/9.96G [00:09<00:30, 247MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  25%|██▌       | 2.54G/9.96G [00:09<00:30, 240MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  26%|██▌       | 2.57G/9.96G [00:09<00:31, 235MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  26%|██▌       | 2.60G/9.96G [00:09<00:31, 233MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  26%|██▋       | 2.63G/9.96G [00:09<00:30, 241MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  27%|██▋       | 2.66G/9.96G [00:09<00:29, 246MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  27%|██▋       | 2.69G/9.96G [00:10<00:30, 237MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  27%|██▋       | 2.73G/9.96G [00:10<00:30, 237MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  28%|██▊       | 2.76G/9.96G [00:10<00:30, 238MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  28%|██▊       | 2.79G/9.96G [00:10<00:32, 221MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  28%|██▊       | 2.82G/9.96G [00:10<00:30, 234MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  29%|██▊       | 2.85G/9.96G [00:10<00:28, 245MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  29%|██▉       | 2.88G/9.96G [00:10<00:27, 256MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  29%|██▉       | 2.92G/9.96G [00:10<00:26, 264MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  30%|██▉       | 2.95G/9.96G [00:11<00:26, 267MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  30%|██▉       | 2.98G/9.96G [00:11<00:25, 273MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  30%|███       | 3.01G/9.96G [00:11<00:24, 279MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  31%|███       | 3.04G/9.96G [00:11<00:24, 280MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  31%|███       | 3.07G/9.96G [00:11<00:24, 276MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  31%|███       | 3.10G/9.96G [00:11<00:25, 268MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  31%|███▏      | 3.14G/9.96G [00:11<00:26, 260MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  32%|███▏      | 3.17G/9.96G [00:11<00:27, 246MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  32%|███▏      | 3.20G/9.96G [00:12<00:27, 242MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  32%|███▏      | 3.23G/9.96G [00:12<00:28, 238MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  33%|███▎      | 3.26G/9.96G [00:12<00:26, 248MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  33%|███▎      | 3.29G/9.96G [00:12<00:25, 259MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  33%|███▎      | 3.32G/9.96G [00:12<00:25, 261MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  34%|███▎      | 3.36G/9.96G [00:12<00:24, 269MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  34%|███▍      | 3.39G/9.96G [00:12<00:23, 276MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  34%|███▍      | 3.42G/9.96G [00:12<00:23, 280MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  35%|███▍      | 3.45G/9.96G [00:12<00:23, 280MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  35%|███▍      | 3.48G/9.96G [00:13<00:23, 279MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  35%|███▌      | 3.51G/9.96G [00:13<00:22, 287MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  36%|███▌      | 3.55G/9.96G [00:13<00:21, 300MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  36%|███▌      | 3.60G/9.96G [00:13<00:20, 312MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  37%|███▋      | 3.64G/9.96G [00:13<00:19, 320MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  37%|███▋      | 3.68G/9.96G [00:13<00:19, 324MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  37%|███▋      | 3.72G/9.96G [00:13<00:19, 325MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  38%|███▊      | 3.76G/9.96G [00:13<00:19, 324MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  38%|███▊      | 3.81G/9.96G [00:14<00:18, 330MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  39%|███▊      | 3.85G/9.96G [00:14<00:18, 332MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  39%|███▉      | 3.89G/9.96G [00:14<00:18, 334MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  39%|███▉      | 3.93G/9.96G [00:14<00:18, 330MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  40%|███▉      | 3.97G/9.96G [00:14<00:18, 329MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  40%|████      | 4.02G/9.96G [00:14<00:17, 331MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  41%|████      | 4.06G/9.96G [00:14<00:17, 334MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  41%|████      | 4.10G/9.96G [00:15<00:20, 293MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  41%|████▏     | 4.13G/9.96G [00:15<00:19, 296MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  42%|████▏     | 4.16G/9.96G [00:15<00:19, 299MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  42%|████▏     | 4.20G/9.96G [00:15<00:18, 307MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  43%|████▎     | 4.24G/9.96G [00:15<00:19, 290MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  43%|████▎     | 4.27G/9.96G [00:15<00:19, 290MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  43%|████▎     | 4.30G/9.96G [00:15<00:19, 285MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  43%|████▎     | 4.33G/9.96G [00:15<00:19, 288MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  44%|████▍     | 4.36G/9.96G [00:15<00:19, 287MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  44%|████▍     | 4.39G/9.96G [00:16<00:19, 288MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  44%|████▍     | 4.42G/9.96G [00:16<00:19, 285MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  45%|████▍     | 4.47G/9.96G [00:16<00:18, 300MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  45%|████▌     | 4.51G/9.96G [00:16<00:17, 318MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  46%|████▌     | 4.55G/9.96G [00:16<00:16, 324MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  46%|████▌     | 4.59G/9.96G [00:16<00:16, 334MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  47%|████▋     | 4.63G/9.96G [00:16<00:15, 341MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  47%|████▋     | 4.68G/9.96G [00:16<00:15, 348MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  47%|████▋     | 4.72G/9.96G [00:16<00:14, 352MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  48%|████▊     | 4.76G/9.96G [00:17<00:14, 348MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  48%|████▊     | 4.80G/9.96G [00:17<00:14, 347MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  49%|████▊     | 4.84G/9.96G [00:17<00:15, 339MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  49%|████▉     | 4.89G/9.96G [00:17<00:16, 312MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  49%|████▉     | 4.93G/9.96G [00:17<00:17, 296MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  50%|████▉     | 4.96G/9.96G [00:17<00:17, 293MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  50%|█████     | 4.99G/9.96G [00:17<00:17, 288MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  50%|█████     | 5.02G/9.96G [00:18<00:18, 260MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  51%|█████     | 5.05G/9.96G [00:18<00:21, 229MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  51%|█████     | 5.09G/9.96G [00:18<00:23, 205MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  51%|█████▏    | 5.12G/9.96G [00:18<00:21, 226MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  52%|█████▏    | 5.15G/9.96G [00:18<00:28, 169MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  52%|█████▏    | 5.18G/9.96G [00:18<00:26, 177MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  52%|█████▏    | 5.21G/9.96G [00:19<00:24, 191MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  53%|█████▎    | 5.24G/9.96G [00:19<00:22, 213MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  53%|█████▎    | 5.27G/9.96G [00:19<00:21, 222MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  53%|█████▎    | 5.31G/9.96G [00:19<00:19, 237MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  54%|█████▎    | 5.34G/9.96G [00:19<00:19, 240MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  54%|█████▍    | 5.37G/9.96G [00:19<00:19, 232MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  54%|█████▍    | 5.40G/9.96G [00:19<00:21, 212MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  55%|█████▍    | 5.43G/9.96G [00:20<00:24, 182MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  55%|█████▍    | 5.45G/9.96G [00:20<00:25, 180MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  55%|█████▍    | 5.47G/9.96G [00:20<00:25, 179MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  55%|█████▌    | 5.49G/9.96G [00:20<00:25, 178MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  55%|█████▌    | 5.52G/9.96G [00:20<00:24, 184MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  56%|█████▌    | 5.55G/9.96G [00:20<00:21, 207MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  56%|█████▌    | 5.58G/9.96G [00:20<00:19, 226MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  56%|█████▋    | 5.61G/9.96G [00:20<00:18, 240MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  57%|█████▋    | 5.64G/9.96G [00:21<00:17, 252MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  57%|█████▋    | 5.67G/9.96G [00:21<00:16, 258MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  57%|█████▋    | 5.70G/9.96G [00:21<00:17, 237MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  58%|█████▊    | 5.74G/9.96G [00:21<00:17, 237MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  58%|█████▊    | 5.77G/9.96G [00:21<00:16, 249MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  58%|█████▊    | 5.80G/9.96G [00:21<00:16, 254MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  59%|█████▊    | 5.83G/9.96G [00:21<00:15, 260MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  59%|█████▉    | 5.87G/9.96G [00:21<00:14, 281MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  59%|█████▉    | 5.91G/9.96G [00:22<00:13, 289MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  60%|█████▉    | 5.95G/9.96G [00:22<00:13, 293MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  60%|██████    | 5.99G/9.96G [00:22<00:13, 302MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  61%|██████    | 6.03G/9.96G [00:22<00:12, 312MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  61%|██████    | 6.07G/9.96G [00:22<00:12, 314MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  61%|██████▏   | 6.11G/9.96G [00:22<00:12, 318MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  62%|██████▏   | 6.16G/9.96G [00:22<00:11, 321MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  62%|██████▏   | 6.20G/9.96G [00:22<00:11, 322MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  63%|██████▎   | 6.24G/9.96G [00:23<00:11, 324MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  63%|██████▎   | 6.28G/9.96G [00:23<00:11, 325MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  63%|██████▎   | 6.32G/9.96G [00:23<00:11, 314MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  64%|██████▍   | 6.36G/9.96G [00:23<00:11, 322MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  64%|██████▍   | 6.41G/9.96G [00:23<00:11, 310MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  65%|██████▍   | 6.44G/9.96G [00:23<00:11, 299MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  65%|██████▍   | 6.47G/9.96G [00:23<00:12, 289MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  65%|██████▌   | 6.50G/9.96G [00:23<00:12, 280MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  66%|██████▌   | 6.53G/9.96G [00:24<00:12, 274MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  66%|██████▌   | 6.56G/9.96G [00:24<00:12, 280MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  66%|██████▌   | 6.60G/9.96G [00:24<00:11, 281MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  67%|██████▋   | 6.63G/9.96G [00:24<00:11, 286MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  67%|██████▋   | 6.66G/9.96G [00:24<00:11, 286MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  67%|██████▋   | 6.69G/9.96G [00:24<00:11, 282MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  67%|██████▋   | 6.72G/9.96G [00:24<00:12, 267MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  68%|██████▊   | 6.75G/9.96G [00:24<00:12, 252MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  68%|██████▊   | 6.78G/9.96G [00:25<00:12, 261MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  68%|██████▊   | 6.82G/9.96G [00:25<00:12, 261MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  69%|██████▊   | 6.85G/9.96G [00:25<00:11, 268MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  69%|██████▉   | 6.88G/9.96G [00:25<00:11, 268MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  69%|██████▉   | 6.91G/9.96G [00:25<00:11, 269MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  70%|██████▉   | 6.94G/9.96G [00:25<00:11, 271MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  70%|███████   | 6.97G/9.96G [00:25<00:11, 270MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  70%|███████   | 7.00G/9.96G [00:25<00:10, 271MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  71%|███████   | 7.04G/9.96G [00:25<00:11, 261MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  71%|███████   | 7.07G/9.96G [00:26<00:11, 261MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  71%|███████▏  | 7.10G/9.96G [00:26<00:10, 263MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  72%|███████▏  | 7.13G/9.96G [00:26<00:10, 265MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  72%|███████▏  | 7.16G/9.96G [00:26<00:12, 227MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  72%|███████▏  | 7.19G/9.96G [00:26<00:13, 207MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  73%|███████▎  | 7.22G/9.96G [00:26<00:12, 223MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  73%|███████▎  | 7.26G/9.96G [00:26<00:11, 237MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  73%|███████▎  | 7.29G/9.96G [00:27<00:10, 248MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  73%|███████▎  | 7.32G/9.96G [00:27<00:10, 257MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  74%|███████▍  | 7.35G/9.96G [00:27<00:10, 259MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  74%|███████▍  | 7.38G/9.96G [00:27<00:09, 262MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  74%|███████▍  | 7.41G/9.96G [00:27<00:09, 268MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  75%|███████▍  | 7.44G/9.96G [00:27<00:10, 242MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  75%|███████▌  | 7.48G/9.96G [00:27<00:10, 235MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  75%|███████▌  | 7.51G/9.96G [00:27<00:10, 232MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  76%|███████▌  | 7.54G/9.96G [00:28<00:10, 230MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  76%|███████▌  | 7.57G/9.96G [00:28<00:10, 229MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  76%|███████▋  | 7.60G/9.96G [00:28<00:10, 232MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  77%|███████▋  | 7.63G/9.96G [00:28<00:10, 231MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  77%|███████▋  | 7.67G/9.96G [00:28<00:09, 236MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  77%|███████▋  | 7.70G/9.96G [00:28<00:09, 238MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  78%|███████▊  | 7.73G/9.96G [00:28<00:09, 232MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  78%|███████▊  | 7.76G/9.96G [00:29<00:09, 233MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  78%|███████▊  | 7.79G/9.96G [00:29<00:09, 229MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  79%|███████▊  | 7.82G/9.96G [00:29<00:09, 230MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  79%|███████▉  | 7.85G/9.96G [00:29<00:09, 231MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  79%|███████▉  | 7.89G/9.96G [00:29<00:09, 230MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  79%|███████▉  | 7.92G/9.96G [00:29<00:08, 233MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  80%|███████▉  | 7.95G/9.96G [00:29<00:10, 197MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  80%|████████  | 7.98G/9.96G [00:30<00:09, 211MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  80%|████████  | 8.01G/9.96G [00:30<00:09, 199MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  81%|████████  | 8.03G/9.96G [00:30<00:11, 172MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  81%|████████  | 8.06G/9.96G [00:30<00:10, 187MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  81%|████████  | 8.08G/9.96G [00:30<00:11, 165MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  81%|████████▏ | 8.11G/9.96G [00:30<00:12, 150MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  82%|████████▏ | 8.14G/9.96G [00:31<00:11, 163MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  82%|████████▏ | 8.16G/9.96G [00:31<00:11, 150MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  82%|████████▏ | 8.18G/9.96G [00:31<00:13, 137MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  82%|████████▏ | 8.20G/9.96G [00:31<00:11, 149MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  83%|████████▎ | 8.22G/9.96G [00:31<00:12, 143MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  83%|████████▎ | 8.24G/9.96G [00:31<00:13, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  83%|████████▎ | 8.27G/9.96G [00:32<00:11, 145MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  83%|████████▎ | 8.29G/9.96G [00:32<00:12, 138MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  83%|████████▎ | 8.32G/9.96G [00:32<00:12, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  84%|████████▎ | 8.34G/9.96G [00:32<00:11, 143MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  84%|████████▍ | 8.36G/9.96G [00:32<00:11, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  84%|████████▍ | 8.38G/9.96G [00:32<00:12, 129MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  84%|████████▍ | 8.40G/9.96G [00:33<00:10, 142MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  85%|████████▍ | 8.42G/9.96G [00:33<00:11, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  85%|████████▍ | 8.44G/9.96G [00:33<00:11, 130MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  85%|████████▍ | 8.46G/9.96G [00:33<00:11, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  85%|████████▌ | 8.48G/9.96G [00:33<00:10, 138MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  85%|████████▌ | 8.50G/9.96G [00:33<00:11, 129MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  86%|████████▌ | 8.52G/9.96G [00:33<00:10, 137MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  86%|████████▌ | 8.55G/9.96G [00:34<00:10, 138MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  86%|████████▌ | 8.57G/9.96G [00:34<00:10, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  86%|████████▌ | 8.59G/9.96G [00:34<00:10, 131MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  86%|████████▋ | 8.61G/9.96G [00:34<00:09, 144MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  87%|████████▋ | 8.63G/9.96G [00:34<00:10, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  87%|████████▋ | 8.65G/9.96G [00:34<00:10, 130MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  87%|████████▋ | 8.67G/9.96G [00:35<00:09, 143MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  87%|████████▋ | 8.69G/9.96G [00:35<00:09, 131MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  87%|████████▋ | 8.71G/9.96G [00:35<00:09, 129MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  88%|████████▊ | 8.73G/9.96G [00:35<00:08, 140MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  88%|████████▊ | 8.76G/9.96G [00:35<00:09, 133MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  88%|████████▊ | 8.78G/9.96G [00:35<00:09, 126MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  88%|████████▊ | 8.80G/9.96G [00:35<00:08, 139MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  89%|████████▊ | 8.82G/9.96G [00:36<00:08, 136MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  89%|████████▊ | 8.84G/9.96G [00:36<00:08, 127MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  89%|████████▉ | 8.86G/9.96G [00:36<00:08, 136MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  89%|████████▉ | 8.88G/9.96G [00:36<00:07, 138MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  89%|████████▉ | 8.90G/9.96G [00:36<00:08, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  90%|████████▉ | 8.92G/9.96G [00:36<00:07, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  90%|████████▉ | 8.94G/9.96G [00:37<00:07, 133MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  90%|█████████ | 8.97G/9.96G [00:37<00:07, 125MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  90%|█████████ | 8.99G/9.96G [00:37<00:07, 127MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  90%|█████████ | 9.01G/9.96G [00:37<00:06, 140MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  91%|█████████ | 9.03G/9.96G [00:37<00:07, 130MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  91%|█████████ | 9.05G/9.96G [00:37<00:06, 130MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  91%|█████████ | 9.07G/9.96G [00:38<00:06, 142MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  91%|█████████▏| 9.09G/9.96G [00:38<00:06, 136MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  91%|█████████▏| 9.11G/9.96G [00:38<00:06, 129MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  92%|█████████▏| 9.13G/9.96G [00:38<00:05, 141MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  92%|█████████▏| 9.15G/9.96G [00:38<00:05, 137MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  92%|█████████▏| 9.18G/9.96G [00:38<00:05, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  92%|█████████▏| 9.20G/9.96G [00:38<00:05, 134MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  93%|█████████▎| 9.22G/9.96G [00:39<00:05, 139MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  93%|█████████▎| 9.24G/9.96G [00:39<00:05, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  93%|█████████▎| 9.26G/9.96G [00:39<00:05, 136MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  93%|█████████▎| 9.28G/9.96G [00:39<00:04, 141MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  93%|█████████▎| 9.30G/9.96G [00:39<00:04, 134MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  94%|█████████▎| 9.32G/9.96G [00:39<00:04, 129MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  94%|█████████▍| 9.34G/9.96G [00:40<00:04, 141MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  94%|█████████▍| 9.36G/9.96G [00:40<00:04, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  94%|█████████▍| 9.38G/9.96G [00:40<00:04, 127MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  94%|█████████▍| 9.41G/9.96G [00:40<00:03, 141MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  95%|█████████▍| 9.43G/9.96G [00:40<00:03, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  95%|█████████▍| 9.45G/9.96G [00:40<00:03, 129MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  95%|█████████▌| 9.47G/9.96G [00:40<00:03, 140MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  95%|█████████▌| 9.49G/9.96G [00:41<00:03, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  95%|█████████▌| 9.51G/9.96G [00:41<00:03, 131MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  96%|█████████▌| 9.53G/9.96G [00:41<00:03, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  96%|█████████▌| 9.55G/9.96G [00:41<00:03, 136MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  96%|█████████▌| 9.57G/9.96G [00:41<00:02, 129MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  96%|█████████▋| 9.59G/9.96G [00:41<00:02, 136MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  97%|█████████▋| 9.62G/9.96G [00:42<00:02, 142MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  97%|█████████▋| 9.64G/9.96G [00:42<00:02, 131MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  97%|█████████▋| 9.66G/9.96G [00:42<00:02, 131MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  97%|█████████▋| 9.68G/9.96G [00:42<00:02, 137MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  97%|█████████▋| 9.70G/9.96G [00:42<00:01, 134MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  98%|█████████▊| 9.72G/9.96G [00:42<00:01, 146MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  98%|█████████▊| 9.74G/9.96G [00:42<00:01, 146MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  98%|█████████▊| 9.76G/9.96G [00:43<00:01, 134MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  98%|█████████▊| 9.78G/9.96G [00:43<00:01, 131MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  98%|█████████▊| 9.80G/9.96G [00:43<00:01, 140MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  99%|█████████▊| 9.83G/9.96G [00:43<00:01, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  99%|█████████▉| 9.85G/9.96G [00:43<00:00, 127MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  99%|█████████▉| 9.87G/9.96G [00:43<00:00, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  99%|█████████▉| 9.89G/9.96G [00:44<00:00, 136MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";:  99%|█████████▉| 9.91G/9.96G [00:44<00:00, 127MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";: 100%|█████████▉| 9.93G/9.96G [00:44<00:00, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";: 100%|█████████▉| 9.95G/9.96G [00:44<00:00, 139MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00001-of-00002.bin\";: 100%|██████████| 9.96G/9.96G [00:44<00:00, 223MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   0%|          | 0.00/3.36G [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   1%|          | 31.5M/3.36G [00:00<00:12, 265MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   2%|▏         | 62.9M/3.36G [00:00<00:13, 247MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   3%|▎         | 94.4M/3.36G [00:00<00:19, 165MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   3%|▎         | 115M/3.36G [00:00<00:20, 162MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   4%|▍         | 136M/3.36G [00:00<00:22, 144MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   5%|▍         | 157M/3.36G [00:01<00:23, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   5%|▌         | 178M/3.36G [00:01<00:21, 145MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   6%|▌         | 199M/3.36G [00:01<00:23, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   7%|▋         | 220M/3.36G [00:01<00:24, 129MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   7%|▋         | 241M/3.36G [00:01<00:22, 136MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   8%|▊         | 262M/3.36G [00:01<00:22, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   8%|▊         | 283M/3.36G [00:01<00:23, 130MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:   9%|▉         | 304M/3.36G [00:02<00:22, 137MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  10%|▉         | 325M/3.36G [00:02<00:22, 136MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  10%|█         | 346M/3.36G [00:02<00:22, 131MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  11%|█         | 367M/3.36G [00:02<00:22, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  12%|█▏        | 388M/3.36G [00:02<00:21, 136MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  12%|█▏        | 409M/3.36G [00:02<00:22, 131MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  13%|█▎        | 430M/3.36G [00:03<00:22, 127MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  13%|█▎        | 451M/3.36G [00:03<00:20, 143MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  14%|█▍        | 472M/3.36G [00:03<00:21, 131MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  15%|█▍        | 493M/3.36G [00:03<00:22, 127MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  16%|█▌        | 524M/3.36G [00:03<00:19, 143MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  16%|█▌        | 545M/3.36G [00:03<00:21, 133MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  17%|█▋        | 566M/3.36G [00:04<00:21, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  17%|█▋        | 587M/3.36G [00:04<00:20, 137MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  18%|█▊        | 608M/3.36G [00:04<00:21, 129MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  19%|█▊        | 629M/3.36G [00:04<00:21, 128MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  19%|█▉        | 650M/3.36G [00:04<00:19, 142MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  20%|█▉        | 671M/3.36G [00:04<00:20, 134MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  21%|██        | 692M/3.36G [00:05<00:20, 130MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  21%|██        | 713M/3.36G [00:05<00:18, 142MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  22%|██▏       | 734M/3.36G [00:05<00:19, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  22%|██▏       | 755M/3.36G [00:05<00:20, 130MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  23%|██▎       | 776M/3.36G [00:05<00:19, 136MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  24%|██▎       | 797M/3.36G [00:05<00:18, 137MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  24%|██▍       | 818M/3.36G [00:05<00:19, 131MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  25%|██▍       | 839M/3.36G [00:06<00:18, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  26%|██▌       | 860M/3.36G [00:06<00:17, 142MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  26%|██▌       | 881M/3.36G [00:06<00:19, 130MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  27%|██▋       | 902M/3.36G [00:06<00:18, 131MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  27%|██▋       | 923M/3.36G [00:06<00:17, 140MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  28%|██▊       | 944M/3.36G [00:06<00:18, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  29%|██▊       | 965M/3.36G [00:07<00:18, 127MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  29%|██▉       | 986M/3.36G [00:07<00:16, 142MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  30%|██▉       | 1.01G/3.36G [00:07<00:17, 136MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  31%|███       | 1.03G/3.36G [00:07<00:18, 126MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  31%|███       | 1.05G/3.36G [00:07<00:16, 140MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  32%|███▏      | 1.07G/3.36G [00:07<00:16, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  32%|███▏      | 1.09G/3.36G [00:08<00:17, 128MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  33%|███▎      | 1.11G/3.36G [00:08<00:16, 139MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  34%|███▎      | 1.13G/3.36G [00:08<00:16, 138MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  34%|███▍      | 1.15G/3.36G [00:08<00:16, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  35%|███▍      | 1.17G/3.36G [00:08<00:15, 137MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  36%|███▌      | 1.20G/3.36G [00:08<00:15, 138MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  36%|███▌      | 1.22G/3.36G [00:08<00:16, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  37%|███▋      | 1.24G/3.36G [00:09<00:16, 129MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  37%|███▋      | 1.26G/3.36G [00:09<00:14, 140MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  38%|███▊      | 1.28G/3.36G [00:09<00:15, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  39%|███▊      | 1.30G/3.36G [00:09<00:15, 129MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  39%|███▉      | 1.32G/3.36G [00:09<00:15, 129MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  40%|███▉      | 1.34G/3.36G [00:09<00:16, 123MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  41%|████      | 1.36G/3.36G [00:10<00:18, 109MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  41%|████      | 1.38G/3.36G [00:10<00:19, 103MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  42%|████▏     | 1.41G/3.36G [00:10<00:20, 96.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  42%|████▏     | 1.43G/3.36G [00:10<00:18, 103MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  43%|████▎     | 1.45G/3.36G [00:10<00:17, 107MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  44%|████▎     | 1.47G/3.36G [00:11<00:17, 109MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  44%|████▍     | 1.49G/3.36G [00:11<00:17, 110MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  45%|████▍     | 1.51G/3.36G [00:11<00:16, 112MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  46%|████▌     | 1.53G/3.36G [00:11<00:16, 112MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  46%|████▌     | 1.55G/3.36G [00:11<00:15, 114MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  47%|████▋     | 1.57G/3.36G [00:12<00:15, 114MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  47%|████▋     | 1.59G/3.36G [00:12<00:15, 115MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  48%|████▊     | 1.61G/3.36G [00:12<00:15, 113MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  49%|████▊     | 1.64G/3.36G [00:12<00:15, 114MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  49%|████▉     | 1.66G/3.36G [00:12<00:14, 114MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  50%|████▉     | 1.68G/3.36G [00:13<00:14, 114MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  51%|█████     | 1.70G/3.36G [00:13<00:14, 112MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  51%|█████     | 1.72G/3.36G [00:13<00:14, 113MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  52%|█████▏    | 1.74G/3.36G [00:13<00:14, 113MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  52%|█████▏    | 1.76G/3.36G [00:13<00:13, 115MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  53%|█████▎    | 1.78G/3.36G [00:13<00:13, 113MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  54%|█████▎    | 1.80G/3.36G [00:14<00:13, 115MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  54%|█████▍    | 1.82G/3.36G [00:14<00:13, 116MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  55%|█████▍    | 1.85G/3.36G [00:14<00:13, 114MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  56%|█████▌    | 1.87G/3.36G [00:14<00:13, 114MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  56%|█████▌    | 1.89G/3.36G [00:14<00:12, 115MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  57%|█████▋    | 1.91G/3.36G [00:15<00:12, 114MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  57%|█████▋    | 1.93G/3.36G [00:15<00:12, 115MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  58%|█████▊    | 1.95G/3.36G [00:15<00:12, 115MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  59%|█████▊    | 1.97G/3.36G [00:15<00:11, 116MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  59%|█████▉    | 1.99G/3.36G [00:15<00:10, 126MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  60%|█████▉    | 2.01G/3.36G [00:15<00:11, 121MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  61%|██████    | 2.03G/3.36G [00:16<00:10, 120MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  61%|██████    | 2.06G/3.36G [00:16<00:10, 125MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  62%|██████▏   | 2.08G/3.36G [00:16<00:09, 136MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  62%|██████▏   | 2.10G/3.36G [00:16<00:09, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  63%|██████▎   | 2.12G/3.36G [00:16<00:08, 141MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  64%|██████▎   | 2.14G/3.36G [00:16<00:07, 155MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  64%|██████▍   | 2.16G/3.36G [00:16<00:08, 142MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  65%|██████▍   | 2.18G/3.36G [00:17<00:08, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  66%|██████▌   | 2.21G/3.36G [00:17<00:06, 164MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  67%|██████▋   | 2.23G/3.36G [00:17<00:07, 158MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  67%|██████▋   | 2.25G/3.36G [00:17<00:07, 142MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  68%|██████▊   | 2.28G/3.36G [00:17<00:07, 147MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  69%|██████▊   | 2.31G/3.36G [00:17<00:06, 171MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  69%|██████▉   | 2.33G/3.36G [00:18<00:06, 149MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  70%|██████▉   | 2.35G/3.36G [00:18<00:06, 155MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  71%|███████   | 2.38G/3.36G [00:18<00:05, 172MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  72%|███████▏  | 2.40G/3.36G [00:18<00:06, 152MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  72%|███████▏  | 2.42G/3.36G [00:18<00:06, 152MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  73%|███████▎  | 2.45G/3.36G [00:18<00:05, 169MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  74%|███████▎  | 2.47G/3.36G [00:18<00:05, 153MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  74%|███████▍  | 2.50G/3.36G [00:19<00:05, 146MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  75%|███████▌  | 2.53G/3.36G [00:19<00:04, 167MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  76%|███████▌  | 2.55G/3.36G [00:19<00:05, 151MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  77%|███████▋  | 2.57G/3.36G [00:19<00:05, 143MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  77%|███████▋  | 2.60G/3.36G [00:19<00:04, 157MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  78%|███████▊  | 2.62G/3.36G [00:19<00:04, 153MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  79%|███████▊  | 2.64G/3.36G [00:20<00:05, 140MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  79%|███████▉  | 2.66G/3.36G [00:20<00:04, 152MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  80%|████████  | 2.69G/3.36G [00:20<00:04, 157MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  81%|████████  | 2.72G/3.36G [00:20<00:04, 141MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  82%|████████▏ | 2.75G/3.36G [00:20<00:03, 165MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  82%|████████▏ | 2.77G/3.36G [00:20<00:03, 151MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  83%|████████▎ | 2.79G/3.36G [00:21<00:04, 140MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  84%|████████▍ | 2.82G/3.36G [00:21<00:03, 162MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  85%|████████▍ | 2.84G/3.36G [00:21<00:03, 148MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  85%|████████▌ | 2.86G/3.36G [00:21<00:03, 139MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  86%|████████▌ | 2.88G/3.36G [00:21<00:03, 149MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  87%|████████▋ | 2.90G/3.36G [00:21<00:03, 150MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  87%|████████▋ | 2.93G/3.36G [00:21<00:03, 140MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  88%|████████▊ | 2.95G/3.36G [00:22<00:02, 143MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  88%|████████▊ | 2.97G/3.36G [00:22<00:02, 155MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  89%|████████▉ | 2.99G/3.36G [00:22<00:02, 138MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  90%|████████▉ | 3.01G/3.36G [00:22<00:02, 135MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  91%|█████████ | 3.04G/3.36G [00:22<00:02, 153MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  91%|█████████ | 3.06G/3.36G [00:22<00:02, 142MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  92%|█████████▏| 3.08G/3.36G [00:23<00:01, 138MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  92%|█████████▏| 3.10G/3.36G [00:23<00:01, 152MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  93%|█████████▎| 3.12G/3.36G [00:23<00:01, 147MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  94%|█████████▎| 3.15G/3.36G [00:23<00:01, 137MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  94%|█████████▍| 3.17G/3.36G [00:23<00:01, 144MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  95%|█████████▍| 3.19G/3.36G [00:23<00:01, 150MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  96%|█████████▌| 3.21G/3.36G [00:23<00:01, 139MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  96%|█████████▌| 3.23G/3.36G [00:24<00:00, 138MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  97%|█████████▋| 3.25G/3.36G [00:24<00:00, 151MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  97%|█████████▋| 3.27G/3.36G [00:24<00:00, 142MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  98%|█████████▊| 3.29G/3.36G [00:24<00:00, 132MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  99%|█████████▊| 3.31G/3.36G [00:24<00:00, 148MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";:  99%|█████████▉| 3.33G/3.36G [00:24<00:00, 142MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";: 100%|█████████▉| 3.36G/3.36G [00:25<00:00, 129MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)00002-of-00002.bin\";: 100%|██████████| 3.36G/3.36G [00:25<00:00, 134MB/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mKilled\u001b[0m\n",
      "\u001b[34m2023-02-27 19:54:24,006 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-02-27 19:54:24,007 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 137 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-02-27 19:54:24,007 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2023-02-27 19:54:24,007 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 137\u001b[0m\n",
      "\u001b[34mErrorMessage \"\"\u001b[0m\n",
      "\u001b[34mExtraInfo \"OutOfMemory: Process killed by SIGKILL (signal 9)\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.8 train-fine-tune.py\"\u001b[0m\n",
      "\u001b[34m2023-02-27 19:54:24,007 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2023-02-27 19:54:52 Uploading - Uploading generated training model\n",
      "2023-02-27 19:54:52 Failed - Resource retained for reuse\n",
      "ProfilerReport-1677527166: NoIssuesFound\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job hf-peft-optj6-2023-02-27-19-46-06-030: Failed. Reason: ClientError: Please use an instance type with more memory, or reduce the size of training data processed on an instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-28be9b2c12b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/workflow/pipeline_context.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_StepArguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrieve_caller_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2246\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2247\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2248\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   4094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4097\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4098\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3625\u001b[0m                     \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m                 )\n\u001b[0;32m-> 3627\u001b[0;31m             raise exceptions.UnexpectedStatusException(\n\u001b[0m\u001b[1;32m   3628\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3629\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job hf-peft-optj6-2023-02-27-19-46-06-030: Failed. Reason: ClientError: Please use an instance type with more memory, or reduce the size of training data processed on an instance."
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb759bc-7040-4447-9c3f-aa1fa0c7ab34",
   "metadata": {},
   "source": [
    "## Fine-tuning OPT6.7B parameter model using PEFT\n",
    "PEFT approaches enable you to get performance comparable to full fine-tuning while only having a small number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc03eac0-7752-4b20-9ccf-519369898f45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mCUDA_VISIBLE_DEVICES\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = \u001b[33m\"\u001b[39;49;00m\u001b[33m0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minstall\u001b[39;49;00m(package):\u001b[37m\u001b[39;49;00m\n",
      "    subprocess.check_call([sys.executable, \u001b[33m\"\u001b[39;49;00m\u001b[33m-m\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minstall\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, package])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "install(\u001b[33m\"\u001b[39;49;00m\u001b[33mgit+https://github.com/huggingface/transformers.git@main\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "install(\u001b[33m\"\u001b[39;49;00m\u001b[33mgit+https://github.com/huggingface/peft.git\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mbitsandbytes\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mbnb\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m AutoTokenizer, AutoConfig, AutoModelForCausalLM\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpeft\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m prepare_model_for_int8_training\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdatasets\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m load_dataset\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpeft\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LoraConfig, get_peft_model\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mprint_trainable_parameters\u001b[39;49;00m(model):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    Prints the number of trainable parameters in the model.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    trainable_params = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    all_param = \u001b[34m0\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m _, param \u001b[35min\u001b[39;49;00m model.named_parameters():\u001b[37m\u001b[39;49;00m\n",
      "        all_param += param.numel()\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mif\u001b[39;49;00m param.requires_grad:\u001b[37m\u001b[39;49;00m\n",
      "            trainable_params += param.numel()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mtrainable params: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtrainable_params\u001b[33m}\u001b[39;49;00m\u001b[33m || all params: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mall_param\u001b[33m}\u001b[39;49;00m\u001b[33m || trainable%: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[34m100\u001b[39;49;00m\u001b[37m \u001b[39;49;00m*\u001b[37m \u001b[39;49;00mtrainable_params\u001b[37m \u001b[39;49;00m/\u001b[37m \u001b[39;49;00mall_param\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(args):\u001b[37m\u001b[39;49;00m\n",
      "    model = AutoModelForCausalLM.from_pretrained(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mfacebook/opt-6.7b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[37m\u001b[39;49;00m\n",
      "        load_in_8bit=\u001b[34mTrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        device_map=\u001b[33m\"\u001b[39;49;00m\u001b[33mauto\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    tokenizer = AutoTokenizer.from_pretrained(\u001b[33m\"\u001b[39;49;00m\u001b[33mfacebook/opt-6.7b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, use_fast=\u001b[34mFalse\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    tokenizer.add_special_tokens({\u001b[33m'\u001b[39;49;00m\u001b[33mpad_token\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33m[PAD]\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m})\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    model = prepare_model_for_int8_training(model)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    config = LoraConfig(\u001b[37m\u001b[39;49;00m\n",
      "        r=\u001b[34m16\u001b[39;49;00m, lora_alpha=\u001b[34m32\u001b[39;49;00m, target_modules=[\u001b[33m\"\u001b[39;49;00m\u001b[33mq_proj\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mv_proj\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], lora_dropout=\u001b[34m0.05\u001b[39;49;00m, bias=\u001b[33m\"\u001b[39;49;00m\u001b[33mnone\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, task_type=\u001b[33m\"\u001b[39;49;00m\u001b[33mCAUSAL_LM\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    model = get_peft_model(model, config)\u001b[37m\u001b[39;49;00m\n",
      "    print_trainable_parameters(model)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    data = load_dataset(\u001b[33m\"\u001b[39;49;00m\u001b[33mAbirate/english_quotes\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    data = data.map(\u001b[34mlambda\u001b[39;49;00m samples: tokenizer(samples[\u001b[33m\"\u001b[39;49;00m\u001b[33mquote\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]), batched=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    trainer = transformers.Trainer(\u001b[37m\u001b[39;49;00m\n",
      "        model=model,\u001b[37m\u001b[39;49;00m\n",
      "        train_dataset=data[\u001b[33m\"\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "        args=transformers.TrainingArguments(\u001b[37m\u001b[39;49;00m\n",
      "            per_device_train_batch_size=args.per_device_train_batch_size,\u001b[37m\u001b[39;49;00m\n",
      "            gradient_accumulation_steps=args.gradient_accumulation_steps,\u001b[37m\u001b[39;49;00m\n",
      "            warmup_steps=args.warmup_steps,\u001b[37m\u001b[39;49;00m\n",
      "            max_steps=args.max_steps,\u001b[37m\u001b[39;49;00m\n",
      "            learning_rate=args.lr,\u001b[37m\u001b[39;49;00m\n",
      "            fp16=args.fp16,\u001b[37m\u001b[39;49;00m\n",
      "            logging_steps=args.logging_steps,\u001b[37m\u001b[39;49;00m\n",
      "            output_dir=args.model_dir,\u001b[37m\u001b[39;49;00m\n",
      "        ),\u001b[37m\u001b[39;49;00m\n",
      "        data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=\u001b[34mFalse\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    model.config.use_cache = \u001b[34mFalse\u001b[39;49;00m  \u001b[37m# silence the warnings.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    trainer.train()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# save the model \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    model.save_pretrained(args.model_dir) \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m(): \u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# parsing the hyperparameters\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m2\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--per_device_train_batch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m4\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--gradient_accumulation_steps\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m4\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--warmup_steps\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m100\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--max_steps\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m200\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m2e-4\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--fp16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mbool\u001b[39;49;00m, default=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--logging_steps\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--device\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test_batch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m8\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# PyTorch container environment variables for data, model, and output directories\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m\"\u001b[39;49;00m\u001b[33m--save-model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, action=\u001b[33m\"\u001b[39;49;00m\u001b[33mstore_true\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, default=\u001b[34mTrue\u001b[39;49;00m, help=\u001b[33m\"\u001b[39;49;00m\u001b[33mFor Saving the current Model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    args, _ = parser.parse_known_args()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# call the train function to start training the model.\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train(args)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    main()\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize code/train-peft.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71788269-35f9-45a4-a821-15c6e0531abb",
   "metadata": {},
   "source": [
    "## Understanding the training script\n",
    "\n",
    "### Step 1 - Load the model\n",
    "In the screenshot below, note that we are loading the model in 8-bit, which would require around 7GB of memory instead of 13GB if we load the model in half-precision (float16). \n",
    "\n",
    "<!-- ![](images/load_model.png) -->\n",
    "<img src=\"images/load_model.png\"  width=\"500\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4bb831-44d0-46f5-b3f0-96973dc07bfd",
   "metadata": {},
   "source": [
    "### Step 2 - Prepare model for training\n",
    "\n",
    "Some pre-processing needs to be done before training such an int8 model using `peft`, therefore let's import an utiliy function `prepare_model_for_int8_training` that will: \n",
    "- Cast the layer norm in `float32` for stability purposes\n",
    "- Add a `forward_hook` to the input embedding layer to enable gradient computation of the input hidden states\n",
    "- Enable gradient checkpointing for more memory-efficient training\n",
    "- Cast the output logits in `float32` for smoother sampling during the sampling procedure\n",
    "\n",
    "`model = prepare_model_for_int8_training(model)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa3dd73-f578-4dda-81d7-e155c62726d4",
   "metadata": {},
   "source": [
    "### Step 3 - Apply LoRA\n",
    "\n",
    "Let's load a `PeftModel` and specify that we are going to use low-rank adapters (LoRA) using `get_peft_model` utility function from `peft`.\n",
    "<img src=\"images/prepare_model_apply_lora.png\"  width=\"800\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7077cd69-3694-4fe7-9383-2acd0f693df5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define metrics\n",
    "metric_definitions = [{\"Name\": \"loss\", \"Regex\": \"'loss': ([0-9\\\\.]+)\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84c17bdb-5882-44cc-929d-709bc6d1c2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "estimator = HuggingFace(\n",
    "    base_job_name=\"hf-peft-optj6\",\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"train-peft.py\",\n",
    "    role=role,\n",
    "    transformers_version='4.17',\n",
    "    pytorch_version='1.10',\n",
    "    py_version='py38',\n",
    "    instance_count=1,\n",
    "    # For training with ml.g5.2xlarge instance, which has 1GPU and 24GB of GPU Memory\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    debugger_hook_config=False,\n",
    "    metric_definitions=metric_definitions,\n",
    "    keep_alive_period_in_seconds=15*60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe112e44-fe3c-49ca-b50f-53db672b2e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: hf-peft-optj6-2023-02-27-23-15-23-077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-27 23:15:23 Starting - Starting the training job...\n",
      "2023-02-27 23:15:47 Starting - Preparing the instances for trainingProfilerReport-1677539723: InProgress\n",
      "......\n",
      "2023-02-27 23:16:52 Downloading - Downloading input data\n",
      "2023-02-27 23:16:52 Training - Downloading the training image........\u001b[34m82%|████████▏ | 164/200 [11:23<02:24,  4.00s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0314, 'learning_rate': 7.2e-05, 'epoch': 1.05}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 164/200 [11:23<02:24,  4.00s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▎ | 165/200 [11:27<02:15,  3.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.8068, 'learning_rate': 7e-05, 'epoch': 1.06}\u001b[0m\n",
      "\u001b[34m82%|████████▎ | 165/200 [11:27<02:15,  3.86s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 166/200 [11:30<02:07,  3.74s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.7299, 'learning_rate': 6.800000000000001e-05, 'epoch': 1.06}\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 166/200 [11:30<02:07,  3.74s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 167/200 [11:36<02:24,  4.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.7871, 'learning_rate': 6.6e-05, 'epoch': 1.07}\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 167/200 [11:36<02:24,  4.38s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 168/200 [11:39<02:11,  4.12s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.869, 'learning_rate': 6.400000000000001e-05, 'epoch': 1.08}\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 168/200 [11:39<02:11,  4.12s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 169/200 [11:44<02:13,  4.31s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0668, 'learning_rate': 6.2e-05, 'epoch': 1.08}\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 169/200 [11:44<02:13,  4.31s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 170/200 [11:48<02:06,  4.21s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.9127, 'learning_rate': 6e-05, 'epoch': 1.09}\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 170/200 [11:48<02:06,  4.21s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 171/200 [11:53<02:06,  4.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.7781, 'learning_rate': 5.8e-05, 'epoch': 1.1}\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 171/200 [11:53<02:06,  4.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 172/200 [11:56<01:55,  4.13s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.5513, 'learning_rate': 5.6000000000000006e-05, 'epoch': 1.1}\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 172/200 [11:56<01:55,  4.13s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 173/200 [12:00<01:47,  3.97s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.135, 'learning_rate': 5.4000000000000005e-05, 'epoch': 1.11}\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 173/200 [12:00<01:47,  3.97s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 174/200 [12:04<01:39,  3.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0992, 'learning_rate': 5.2000000000000004e-05, 'epoch': 1.11}\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 174/200 [12:04<01:39,  3.83s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 175/200 [12:08<01:38,  3.96s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.8761, 'learning_rate': 5e-05, 'epoch': 1.12}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 175/200 [12:08<01:38,  3.96s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 176/200 [12:11<01:31,  3.81s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.3899, 'learning_rate': 4.8e-05, 'epoch': 1.13}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 176/200 [12:11<01:31,  3.81s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 177/200 [12:22<02:12,  5.76s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1251, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.13}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 177/200 [12:22<02:12,  5.76s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 178/200 [12:25<01:51,  5.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.3234, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.14}\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 178/200 [12:25<01:51,  5.06s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 179/200 [12:28<01:35,  4.54s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6693, 'learning_rate': 4.2e-05, 'epoch': 1.15}\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 179/200 [12:28<01:35,  4.54s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 180/200 [12:32<01:26,  4.31s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6696, 'learning_rate': 4e-05, 'epoch': 1.15}\u001b[0m\n",
      "\u001b[34m90%|█████████ | 180/200 [12:32<01:26,  4.31s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 181/200 [12:35<01:16,  4.02s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.8816, 'learning_rate': 3.8e-05, 'epoch': 1.16}\u001b[0m\n",
      "\u001b[34m90%|█████████ | 181/200 [12:35<01:16,  4.02s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 182/200 [12:39<01:10,  3.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.4149, 'learning_rate': 3.6e-05, 'epoch': 1.17}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 182/200 [12:39<01:10,  3.90s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 183/200 [12:43<01:03,  3.76s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6356, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.17}\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 183/200 [12:43<01:03,  3.76s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 184/200 [12:46<00:58,  3.64s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2022, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.18}\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 184/200 [12:46<00:58,  3.64s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▎| 185/200 [12:50<00:58,  3.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.8641, 'learning_rate': 3e-05, 'epoch': 1.19}\u001b[0m\n",
      "\u001b[34m92%|█████████▎| 185/200 [12:50<00:58,  3.87s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 186/200 [12:54<00:54,  3.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6707, 'learning_rate': 2.8000000000000003e-05, 'epoch': 1.19}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 186/200 [12:54<00:54,  3.86s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 187/200 [12:57<00:47,  3.67s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.7652, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.2}\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 187/200 [12:57<00:47,  3.67s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 188/200 [13:02<00:46,  3.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.7008, 'learning_rate': 2.4e-05, 'epoch': 1.2}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 188/200 [13:02<00:46,  3.91s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 189/200 [13:06<00:44,  4.02s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0328, 'learning_rate': 2.2000000000000003e-05, 'epoch': 1.21}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 189/200 [13:06<00:44,  4.02s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 190/200 [13:10<00:39,  3.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1862, 'learning_rate': 2e-05, 'epoch': 1.22}\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 190/200 [13:10<00:39,  3.94s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 191/200 [13:16<00:40,  4.51s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1345, 'learning_rate': 1.8e-05, 'epoch': 1.22}\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 191/200 [13:16<00:40,  4.51s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 192/200 [13:19<00:33,  4.19s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2655, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.23}\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 192/200 [13:19<00:33,  4.19s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 193/200 [13:23<00:27,  3.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.9687, 'learning_rate': 1.4000000000000001e-05, 'epoch': 1.24}\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 193/200 [13:23<00:27,  3.95s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 194/200 [13:26<00:23,  3.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.8029, 'learning_rate': 1.2e-05, 'epoch': 1.24}\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 194/200 [13:26<00:23,  3.91s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 195/200 [13:30<00:18,  3.72s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.7791, 'learning_rate': 1e-05, 'epoch': 1.25}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 195/200 [13:30<00:18,  3.72s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 196/200 [13:34<00:15,  3.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.9319, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.26}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 196/200 [13:34<00:15,  3.92s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 197/200 [13:37<00:11,  3.78s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.718, 'learning_rate': 6e-06, 'epoch': 1.26}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 197/200 [13:37<00:11,  3.78s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 198/200 [13:47<00:11,  5.57s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0607, 'learning_rate': 4.000000000000001e-06, 'epoch': 1.27}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 198/200 [13:47<00:11,  5.57s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 199/200 [13:51<00:04,  4.93s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.3976, 'learning_rate': 2.0000000000000003e-06, 'epoch': 1.27}\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 199/200 [13:51<00:04,  4.93s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 200/200 [13:54<00:00,  4.57s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.9365, 'learning_rate': 0.0, 'epoch': 1.28}\u001b[0m\n",
      "\u001b[34m100%|██████████| 200/200 [13:54<00:00,  4.57s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 834.9051, 'train_samples_per_second': 3.833, 'train_steps_per_second': 0.24, 'train_loss': 1.938018873333931, 'epoch': 1.28}\u001b[0m\n",
      "\u001b[34m100%|██████████| 200/200 [13:54<00:00,  4.57s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 200/200 [13:54<00:00,  4.17s/it]\u001b[0m\n",
      "\u001b[34m2023-02-27 23:37:26,895 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-02-27 23:37:26,896 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-02-27 23:37:26,896 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-02-27 23:38:27 Uploading - Uploading generated training model\n",
      "2023-02-27 23:38:27 Completed - Resource retained for reuse\n",
      "Training seconds: 1308\n",
      "Billable seconds: 1308\n"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f090e86a-9276-4a71-b56a-129388cc6351",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check logs for trainingable parameters\n",
    "It should show numbers similar to the following: \n",
    "\n",
    "`trainable params: 7340032 || all params: 6058222816 || trainable%: 0.12115817167725645`\n",
    "\n",
    "indicating that we are only fine-tuning 0.1211% of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea4b125-5ac5-4e29-91d8-bbd901a9f2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare model for inference\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.10-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
